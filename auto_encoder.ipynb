{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, info = tfds.load('eurosat',with_info=True, split='train' )\n",
    "\n",
    "print(f'\\nFeatures: {info.features}')\n",
    "print(f\"Loaded examples: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(data_element):\n",
    "    image = data_element['image']\n",
    "    image = tf.cast(image, tf.float32)/255\n",
    "    shape = tf.shape(image)\n",
    "    noisy = tf.random.normal(shape=tf.shape(image), stddev=0.15, dtype=tf.float32)\n",
    "    noisy_image = tf.clip_by_value(image + noisy, clip_value_min=0, clip_value_max=1)\n",
    "    \n",
    "    return noisy_image, image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.take(25000)\n",
    "train_data = train_data.map(pre_process)\n",
    "train_data = train_data.cache()\n",
    "train_data = train_data.shuffle(buffer_size=2500)\n",
    "train_data = train_data.batch(128)\n",
    "train_data = train_data.prefetch(tf.data.AUTOTUNE)\n",
    "print(train_data.element_spec)\n",
    "\n",
    "test_data = data.skip(25000).take(2000)\n",
    "test_data = test_data.map(pre_process)\n",
    "test_data = test_data.cache()\n",
    "test_data = test_data.batch(32)\n",
    "test_data = test_data.prefetch(tf.data.AUTOTUNE)\n",
    "print(test_data.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_batch, orig_batch = next(iter(test_data))\n",
    "\n",
    "fig, axs = plt.subplots(8, 4, figsize=(8, 8))\n",
    "\n",
    "for ax, noisy, orig in zip(axs.flat, noisy_batch, orig_batch):\n",
    "  combined = tf.concat([noisy, orig], axis=1)\n",
    "  ax.imshow(combined)\n",
    "  ax.axis(\"off\")\n",
    "\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating encoder\n",
    "encoder = tf.keras.Sequential()\n",
    "encoder.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal'))\n",
    "encoder.add(tf.keras.layers.MaxPooling2D())\n",
    "encoder.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "encoder.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal'))\n",
    "encoder.add(tf.keras.layers.MaxPooling2D())\n",
    "encoder.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "encoder.add(tf.keras.layers.Conv2D(filters=128, kernel_size=1, padding='same', activation='relu', kernel_initializer='he_normal'))\n",
    "encoder.add(tf.keras.layers.MaxPooling2D())\n",
    "encoder.add(tf.keras.layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating decoder\n",
    "decoder = tf.keras.Sequential()\n",
    "decoder.add(tf.keras.layers.UpSampling2D())\n",
    "decoder.add(tf.keras.layers.Conv2D(filters=128, kernel_size=1, padding='same', activation='relu', kernel_initializer='he_normal'))\n",
    "decoder.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "decoder.add(tf.keras.layers.UpSampling2D())\n",
    "decoder.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal'))\n",
    "decoder.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "decoder.add(tf.keras.layers.UpSampling2D())\n",
    "decoder.add(tf.keras.layers.Conv2D(filters=32 ,kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal'))\n",
    "decoder.add(tf.keras.layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(64, 64, 3)))\n",
    "model.add(encoder)\n",
    "model.add(tf.keras.layers.Dense(units=32))\n",
    "model.add(decoder)\n",
    "model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=1, padding='same'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(), \n",
    "              loss = tf.keras.losses.MeanAbsoluteError(), \n",
    "              metrics = tf.keras.metrics.MeanAbsolutePercentageError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model\n",
    "history = model.fit(train_data, epochs=35, validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=[10,5])\n",
    "plt.plot(history.history['loss'], 'black', linewidth=2.0)\n",
    "plt.plot(history.history['val_loss'], 'blue', linewidth=2.0)\n",
    "plt.legend(['Training Loss', 'Validation Loss'], fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=10)\n",
    "plt.title('Loss Curves', fontsize=12)\n",
    "\n",
    "plt.figure(figsize=[10,5])\n",
    "plt.plot(history.history['categorical_accuracy'], 'black', linewidth=2.0)  \n",
    "plt.plot(history.history['val_categorical_accuracy'], 'blue', linewidth=2.0)  \n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=10)\n",
    "plt.ylabel('Accuracy', fontsize=10)\n",
    "plt.title('Accuracy Curves', fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
